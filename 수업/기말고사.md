## 퍼셉트론
1. 퍼셉트론 : 로젠 블렛이 1957년에 고안한 알고리즘(인공신경망의 한 종류) (입력-가중합-활성화함수-출력)
2. 신경망의 기본 구조 : 여러 층의 퍼셉트론을 서로 연결시키고 복잡하게 조합하여 주어진 입력 값에 대한판단을 하게 하는 것
3. 퍼셉트론의 한계 : xor 해결 불가, 다층 퍼셉트론(multilayer perceptron), 오차 역전파(back propagation)로 해결
4. 다중 퍼셉트론 : 퍼셉트론 두 개를 각각 처리하는 은닉층(hidden layer)을 입력층과 출력층 사이에 만들어 하나의 퍼셉트론으로 해결되지 않는 문제 해결, nand, or한 결과를 and함 이걸 알아내는데 20년 걸림(인공지능의 겨울)

## 오차역전파
1. 다중퍼셉트론을 쓰더라도 은닉층에 포함된 가중치를 업데이트할 방법이 없음.
2. 오차역전파 : 오차를 점점 거슬러 올라가면서 다시 전파하는 것
3. 델타식을 이용해 깊은 신경망의 계산이 가능
4. 활성화함수:  가중치 업데이트가 처음 층까지 전달되지 않는 현상이 생기는 문제가 발견
5. relu함수로 해결(x가 0보다 작을 때 모든 값을 0으로 처리하고,0보다 큰 값은 x를 그대로 사용하는 방법)
6. 그외 하이퍼볼릭 탄젠트(hyperbolic tangent) 함수, 소프트플러스(softplus) 함수
7. 고급 경사하강법 : 1. 확률적 경사하강법 : 속도가 확연히 빠르면서도 최적 해에 근사한 값을 찾아낸다, ->방향조절 2. 모멘텀(탄성, 가속도) : 경사하강법에 탄성을 더하는 것 -> 3. adam(정확도, 속도 향상)
8. 고급 경사하강법은 optimizer로 간단히 실행 가능, sigmoid, relu도 activation으로 간단히 실행 가능

## 딥러닝모델 설계
1. sequential()함수 : 케라스
2. model.add로 새로운 층 만듦
3. 데이터에서 값을 16개 받아 은닉층의 노드 30개로 보낸다(model.add(Dense(30, input_dim=16, activation='relu')))
4. 활성화 함수로 시그모이드(sigmoid) 함수를 사용(model.add(Dense(1, activation='sigmoid')))
5. adam 사용, 평균 제곱 계열 중 하나 이항 분류로 컴파일 model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
6. 5번 실행, 샘플을 16번씩 끊어 집어넣음(history=model.fit(X, y, epochs=5, batch_size=16))

## 인디언당뇨병

## 다중분류
1. 다중분류 : 여러개 중에서 하나를 고르는 것(이항분류 못씀)
2. 원핫인코딩 :  여러 개의 값으로 된 문자열을 0과 1로만 이루어진 형태로 만들어 주는 과정(get_dummies() 함수)
3. 소프트맥스 : 첫째 출력층의 노드 수가 3으로 바뀜,  활성화 함수가 softmax로 바뀜,  마지막으로 컴파일 부분에서 손실 함수 부분이 categorical_crossentropy로 바뀜(각 샘플당 예측 확률의 총합이 1인 형태로 바꾸어 주게 됨)
4. 다항분류 : model.compile(loss='**categorical_crossentropy**', optimizer='adam', metrics=['accuracy'])
5. 
