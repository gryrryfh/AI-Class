## 1장 딥러닝 시작을 위한 준비 운동
인공지능 안에 머신러닝 딥러닝  
딥러닝 실행을 위해 필요한 3가지 : 데이터, 컴퓨터, 프로그램  
프로그램 : 구글코랩(설치 필요없음, 구글이 다 제공, 세션유지 힘듦), 주피터 노트북(세선유지 제약 없음, 아나콘다 설치) 등  
파이썬 예시(print("Hello, Deeplearning!"))  
탠서플로 설치방법 : import tensorflwo as tf  
from tensorflow.keras.models import Sequential  
from tensorflow.keras.layers import Dense  
import numpy as np  
from 라이브러리 import 함수명  
데이터 준비하고 로드하고??  
텐서플로 : 구글에서 만든 딥러닝 전용 라이브러리    
사용법이 어렵지만 케라스로 해결  
딥러닝은 여러 층이 쌓여 만들어진다는 것  
keras사용예시 : sequential(함수를 모델로 선언), dense(빽빽한 정도)  

``` python  
from tensorflow.keras.models import Sequential  # 텐서플로의 케라스 API에서 필요한 함수들을 불러옵니다.  
from tensorflow.keras.layers import Dense       # 데이터를 다루는데 필요한 라이브러리를 불러옵니다.  
import numpy as np  
Data_set = np.loadtxt("./data/ThoraricSurgery3.csv", delimiter=",") # 준비된 수술 환자 데이터를 불러옵니다.  
X = Data_set[:,0:16]                                                 # 환자의 진찰 기록을 X로 지정합니다.  
y = Data_set[:,16]  
model = Sequential()                                                  # 딥러닝 모델의 구조를 결정합니다.  
model.add(Dense(30, input_dim=16, activation='relu'))  
model.add(Dense(1, activation='sigmoid'))    
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # 딥러닝 모델을 실행합니다.  
history=model.fit(X, y, epochs=5, batch_size=16)  
```  

## 2장 딥러닝을 위한 기초 수학  
기울기=a, y절편=b y=ax+b   a=y증가량/x증가량  
y=a(x-p)^2+q 최솟값 == q  
미분 : 순간변화율을 구하는 것   미분계수==기울기  
원하는 한 가지 변수만 미분하고 그 외에는 모두 상수로 취급하는 것이 편미분  
시그모이드 함수  
  
딥러닝의 내부를 보면 입력받은 신호를 얼마나 출력할지를 계산하는 과정이 무수히 반복  
이때 출력 값으로 얼마나 내보낼지를 계산하는 함수를 활성화 함수라고 함  
활성화 함수는 딥러닝이 발전함에 따라 여러 가지 형태로 개발되어 왔는데, 그중 가장 먼저 배우는 중요한 함수가 바로 시그모이드 함수  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/8ee038e6-e679-4913-8f0f-2f0e8d26938c)  

## 3장  
딥러닝은 자그마한 통계의 결과들이 무수히 얽히고설켜 이루어지는 복잡한 연산의 결정체  
선형 회귀(linerar regression), 로지스틱 회귀  
독립변수, 종속변수  
x값만으로도 y값을 설명할 수 있으면 단순 선형회귀  
x값이 여러개 필요하다면 다중선형회귀  
최소제곱법![image](https://github.com/gryrryfh/AI-Class/assets/50912987/6f900552-4e2a-4e79-a364-8369ae89014e)  
x의 편차(각 값과 평균과의 차이)를 제곱해서 합한 값을    
분모로 놓고, x와 y의 편차를 곱해서 합한 값을 분자로 놓으면 기울기  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/6993ec34-6de4-4aea-b44b-9d510f021165)  
  
오차=실제값-예측값  
평균제곱오차= (오차)^2의 합/n  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/4f7a77fa-3fc5-4ce8-92c8-c91f039f5997)  

### 최소제곱 파이썬  
```python  
import numpy as np  
# 공부한 시간과 점수를 각각 x, y라는 이름의 넘파이 배열로 만듭니다.  
x = np.array([2, 4, 6, 8])  
y = np.array([81, 93, 91, 97])  
#x의 평균값을 구합니다.  
mx = np.mean(x)  
#y의 평균값을 구합니다.  
my = np.mean(y)  
# 출력으로 확인합니다.  
print("x의 평균값:", mx)  
print("y의 평균값:", my)  
# 기울기 공식의 분모 부분입니다.  
divisor = sum([(i - mx)**2 for i in x])  
# 기울기 공식의 분자 부분입니다.  
def top(x, mx, y, my):  
    d = 0  
    for i in range(len(x)):  
        d += (x[i] - mx) * (y[i] - my)  
    return d  
dividend = top(x, mx, y, my)  
# 출력으로 확인합니다.  
print("분모:", divisor)  
print("분자:", dividend)  
# 기울기 a를 구하는 공식입니다.  
a = dividend / divisor  
# y절편 b 를 구하는 공식입니다.  
b = my - (mx*a)  
# 출력으로 확인합니다.  
print("기울기 a =", a)  
print("y절편 b =", b)  
```
### 평균제곱 오차 파이썬  
```python  
#가상의 기울기 a와 y 절편 b를 정합니다.  
fake_a=3  
fake_b=7  
#공부 시간 x와 성적 y의 넘파이 배열을 만듭니다.
x = np.array([2, 4, 6, 8])
y = np.array([81, 93, 91, 97])
# y=ax + b에 가상의 a,b 값을 대입한 결과를 출력하는 함수입니다.
def predict(x):
    return fake_a * x + fake_b
# 예측 값이 들어갈 빈 리스트를 만듭니다.
predict_result = []
# 모든 x값을 한 번씩 대입하여 predict_result 리스트를 완성합니다.
for i in range(len(x)):
    predict_result.append(predict(x[i]))
    print("공부시간=%.f, 실제점수=%.f, 예측점수=%.f" % (x[i], y[i], predict(x[i])))
# 평균 제곱 오차 함수를 각 y값에 대입하여 최종 값을 구하는 함수입니다.
n=len(x)  
def mse(y, y_pred):
    return (1/n) * sum((y - y_pred)**2)
# 평균 제곱 오차 값을 출력합니다.
print("평균 제곱 오차: " + str(mse(y,predict_result)))
```
  
## 4장  
기울기를 너무 크게 잡거나 작게 잡으면 오차가 커짐 적절한 기울기를 찾으면 오차가 최소화된다.  
미분 기울기를 이용하는 경사하강법  
경사하강법 : a의 미분을 구하고 반대방향으로 이동후 또 미분을 구하고 기울기가 0이 될때까지 반복  
경사하강법 : 오차의 변화에 따라 이차 함수 그래프를 만들고 적절한 학습률을 설정해 미분 값이 0인ㅇ 지점을 구하는 것  
학습률은 그때그때 다름..  
epoch는 입력 값에 대해 몇 번이나 반복해서 실헙했는지를 나타냄  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/994d48ed-c58d-4065-a3fa-8efe6209de5f)
### 선형회귀  
```python  
!pip install matplotlib
import numpy as np
import matplotlib.pyplot as plt
#공부 시간 X와 성적 Y의 넘파이 배열을 만듭니다.
x = np.array([2, 4, 6, 8])
y = np.array([81, 93, 91, 97])
# 기울기 a와 절편 b의 값을 초기화합니다.
a = 0
b = 0
#학습률을 정합니다.
lr = 0.03
#몇 번 반복될지를 설정합니다. 
epochs = 2001
# x 값이 총 몇 개인지 셉니다.
n=len(x)
#경사 하강법을 시작합니다.
for i in range(epochs):                  # epoch 수 만큼 반복
    y_pred = a * x + b                   # 예측 값을 구하는 식입니다. 
    error = y - y_pred                   # 실제 값과 비교한 오차를 error로 놓습니다.
    a_diff = (2/n) * sum(-x * (error))   # 오차 함수를 a로 편미분한 값입니다. 
    b_diff = (2/n) * sum(-(error))       # 오차 함수를 b로 편미분한 값입니다. 
    a = a - lr * a_diff     # 학습률을 곱해 기존의 a 값을 업데이트합니다.
    b = b - lr * b_diff     # 학습률을 곱해 기존의 b 값을 업데이트합니다.
    if i % 100 == 0:        # 100번 반복될 때마다 현재의 a 값, b 값을 출력합니다.
        print("epoch=%.f, 기울기=%.04f, 절편=%.04f" % (i, a, b))
#앞서 구한 최종 a값을 기울기, b값을 y절편에 대입하여 그래프를 그립니다.
y_pred = a * x + b      
#그래프 출력
plt.scatter(x, y)
plt.plot(x, y_pred,'r')
plt.show()
```  
### 다중 선형회귀  
여러 변수를 따지는 것  
```python
import numpy as np
import matplotlib.pyplot as plt
#공부 시간 x1과 과외 시간 x2, 그성적 y의 넘파이 배열을 만듭니다. 
x1 = np.array([2, 4, 6, 8])
x2 = np.array([0, 4, 2, 3])
y = np.array([81, 93, 91, 97])
# 데이터의 분포를 그래프로 나타냅니다.
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter3D(x1, x2, y)
plt.show()
# 기울기 a와 절편 b의 값을 초기화합니다.
a1 = 0
a2 = 0
b = 0
#학습률을 정합니다.
lr = 0.01 
#몇 번 반복될지를 설정합니다.
epochs = 2001
# x 값이 총 몇 개인지 셉니다. x1과 x2의 수가 같으므로 x1만 세겠습니다. 
n=len(x1)
#경사 하강법을 시작합니다.
for i in range(epochs):                  # epoch 수 만큼 반복
    y_pred = a1 * x1 + a2 * x2 + b       #예측 값을 구하는 식을 세웁니다
    error = y - y_pred                   #실제 값과 비교한 오차를 error로 놓습니다.
    a1_diff = (2/n) * sum(-x1 * (error)) # 오차함수를 a1로 편미분한 값입니다. 
    a2_diff = (2/n) * sum(-x2 * (error)) # 오차함수를 a2로 편미분한 값입니다. 
    b_diff = (2/n) * sum(-(error))       # 오차함수를 b로 편미분한 값입니다. 
    a1 = a1 - lr * a1_diff  # 학습률을 곱해 기존의 a1 값을 업데이트합니다.
    a2 = a2 - lr * a2_diff  # 학습률을 곱해 기존의 a2 값을 업데이트합니다.
    b = b - lr * b_diff     # 학습률을 곱해 기존의 b 값을 업데이트합니다.
    
    if i % 100 == 0:        # 100번 반복될 때마다 현재의 a1, a2, b 값을 출력합니다.
        print("epoch=%.f, 기울기1=%.04f, 기울기2=%.04f, 절편=%.04f" % (i, a1, a2, b))
#실제 점수와 예측 된 점수를 출력합니다.
print("실제 점수:", y)
print("예측 점수:", y_pred)       
```  
### 텐서플로 선형회귀, 다정 선형회귀  
  
선형회귀는 현상 분석 방법 중 하나  
머신 러닝은 이런 분석 방법을 이용해 예측 모델을 만드는 것  
평균 제곱 오차==손실 함수  
경사하강법 == 옵티마이저  
#### 텐서플로 선형회귀  
```python
import numpy as np
import matplotlib.pyplot as plt
#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
x = np.array([2, 4, 6, 8])
y = np.array([81, 93, 91, 97])
model = Sequential()
# 출력 값, 입력 변수, 분석 방법에 맞게끔 모델을 설정합니다. 
model.add(Dense(1, input_dim=1, activation='linear'))
# 오차 수정을 위해 경사 하강법(sgd)을, 오차의 정도를 판단하기 위해 평균 제곱 오차(mse)를 사용합니다. 
model.compile(optimizer='sgd', loss='mse')
# 오차를 최소화하는 과정을 2000번 반복합니다.
model.fit(x, y, epochs=2000)
plt.scatter(x, y)
plt.plot(x, model.predict(x),'r')    # 예측 결과를 그래프로 나타냅니다.
plt.show()
#임의의 시간을 집어넣어 점수를 예측하는 모델을 테스트해 보겠습니다.
hour = 7
prediction = model.predict([hour])
print("%.f시간을 공부할 경우의 예상 점수는 %.02f점입니다" % (hour, prediction))
```  
#### 텐서플로 다중 선형회귀  
```python  
import numpy as np
import matplotlib.pyplot as plt
#텐서플로의 케라스 API에서 필요한 함수들을 불러 옵니다.
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
x = np.array([[2, 0], [4, 4], [6, 2], [8, 3]])
y = np.array([81, 93, 91, 97])
model = Sequential()
#입력 변수가 2개(학습 시간, 과외 시간)이므로 input_dim에 2를 입력합니다. 
model.add(Dense(1, input_dim=2, activation='linear'))
model.compile(optimizer='sgd' ,loss='mse')
model.fit(x, y, epochs=2000)
#임의의 학습 시간과 과외 시간을 집어넣어 점수를 예측하는 모델을 테스트해 보겠습니다.
hour = 7
private_class = 4
prediction = model.predict([[hour, private_class]])
print("%.f시간을 공부하고 %.f시간의 과외를 받을 경우, 예상 점수는 %.02f점입니다" % (hour, private_class, prediction))
7시간을 공부하고 4시간의 과외를 받을 경우, 예상 점수는 97.53점입니다
```  
## 5장  
예측을 위한 로이스 테이를 사용함  
딥러닝 인공지능에서는 기울기라고 표현 안 하고 웨이트라고 표현함  
평균 제곱 오차는 손실 함수라는 표현을 사용함  
경사하각법은 머릿속에 그려진 2차 함수가 있을 때 기울기 값을 계속 해가지고 0이 될 때까지 구하는 것임  
최적화는 이미의 값을 하나 주고 옆에서부터 계속 값을 찾아내는 과정임  
경사하각법은 옵티마이드로 찾아가는 방법임  
환경 설정이 끝났으면 학습을 시켜야 함  
x와 y는 주어진 값임  
x와 y를 그래프로 그리고 싶으면 파이썬 프합이라는 게 있음 
피처 값으로 테스트를 위해서 데이터 파일로부터 보는 게 아니고 리스크를 줌  
학습을 시켰으니까 예측을 해봐야 함  
학습이 끝나고 새로운 데이터를 주면 학습한 모델에서 어떤 값을 판결해 줄 것인지 예측을 해봐야 함  
예측을 하는 게 신용 행위임  
기본 관리가 안 되면 인터페이스 자료로 쓰고 싶어 하는데 내가 찾는 자료가 맞는지 안 맞는지를 말할 거임  
한계가 있으면 그 과목은 더 안 하게 됨  
1차 함수는 y 값이 무수히 많은 값이 있을 수 있음  
y 값이 x 축이고 x 축이 y 축이니까 y 값이 무수히 많은 값이 있을 수 있음  
일상생활에도 레스모 형태의 문제들이 많음  
우리 머릿속에 1이냐 0이냐의 문제는 로이스템이다 이렇게 머릿속에 딱 가지고 있으면 다 해결됨  
합격이면 1인이랑 합격인 것처럼 에스자 그래프가 필요함  
선형 회기를 먼저 이야기한 이유가 설명 로이스트 회기도 따지고 보면 그래프의 문제다   이 이야기를 하고 싶은 거임  
오차 값이 0에 가까울수록 좋음  
오차 값이 적을 때는 파란색 그래프를 사용하는 게 좋음  
두 개의 그래프를 짬뽕해서 사용할 수 있음  
리니어 문제가 아니고 그래프를 만들어야 됨  
0과 1 사이에 그래프가 그려지니까 가능함  
우리가 지금까지 인간 분해가 몇 개의 인물로 이루어져 있는지 찾아보라고 함  
#### 로지스틱회귀의 정의  
직선으로 해결하기 적절하지 않은 경우, 선을 그려가는 과정 대신 참,거짓(0,1)사이를 구분하는 s자 형태의 선을 그어주는 작업  
시그모이드 함수  
a값이 작으면 오차는 무한대로 커지고 a값이 커진다고 오차가 무한대로 커지지는 않음  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/9235d9bc-8bfa-469a-8030-022c7c1f59a6)  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/e16efc05-e75d-425f-b23c-fe8737356f92)  
오차공식은 로그함수를사용 == 교차 엔트로피 오차  
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/057e17c1-278b-4aaf-b1c7-37acdb7649cd)  
```python  
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
x = np.array([2, 4, 6, 8, 10, 12, 14])
y = np.array([0, 0, 0, 1, 1, 1, 1])
model = Sequential()
model.add(Dense(1, input_dim=1, activation='sigmoid'))
# 교차 엔트로피 오차 함수를 이용하기 위하여 'binary_crossentropy'로 설정합니다. 
model.compile(optimizer='sgd' ,loss='binary_crossentropy')
model.fit(x, y, epochs=5000)
#그래프로 확인해 봅니다.
plt.scatter(x, y)
plt.plot(x, model.predict(x),'r')
plt.show()
#임의의 학습시간을 집어넣어 합격 예상 확률을 예측해 보겠습니다.
hour = 7
prediction = model.predict([hour])
print("%.f시간을 공부할 경우, 합격 예상 확률은 %.01f%%입니다" % (hour, prediction * 100))
```  

