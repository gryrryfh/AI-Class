```python
import numpy as np
# 가중치와 바이어스
w11 = np.array([-2, -2])
w12 = np.array([2, 2])
w2 = np.array([1, 1])
b1 = 3
b2 = -1
b3 = -1
# 퍼셉트론
def MLP(x, w, b):
    y = np.sum(w * x) + b
    if y <= 0:
        return 0
    else:
        return 1
# NAND 게이트
def NAND(x1,x2):
    return MLP(np.array([x1, x2]), w11, b1)
# OR 게이트
def OR(x1,x2):
    return MLP(np.array([x1, x2]), w12, b2)
# AND 게이트
def AND(x1,x2):
    return MLP(np.array([x1, x2]), w2, b3)
# XOR 게이트
def XOR(x1,x2):
    return AND(NAND(x1, x2),OR(x1,x2))
# x1, x2 값을 번갈아 대입해 가며 최종 값 출력
    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:
        y = XOR(x[0], x[1])
        print("입력 값: " + str(x) + " 출력 값: " + str(y))
```
```python
# 텐서플로 라이브러리 안에 있는 케라스 API에서 필요한 함수들을 불러오기
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
# 데이터를 다루는 데 필요한 라이브러리를 불러오기
import numpy as np
# 준비된 수술 환자 데이터를 불러오기
Data_set = np.loadtxt("C:/Users/jaegy/pythonProject2/data/ThoraricSurgery3.csv", delimiter=",")
X = Data_set[:,0:16]    # 환자의 진찰 기록을 X로 지정
y = Data_set[:,16]      # 수술 1년 후 사망/생존 여부를 y로 지정
# 딥러닝 모델의 구조 결정
model = Sequential()
# 30개의 뉴런을 가지고, 입력 차원은 16, 활성화 함수는 ReLU를 사용
model.add(Dense(30, input_dim=16, activation='relu'))
# 시그모이드 함수 사용
model.add(Dense(1, activation='sigmoid'))
# 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 실행
history=model.fit(X, y, epochs=5, batch_size=16)
```
```python
# 텐서플로 라이브러리 안에 있는 케라스 API에서 필요한 함수들을 불러오기
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
# pandas 라이브러리를 불러오기
import pandas as pd
# 피마 인디언 당뇨병 데이터셋을 불러오기
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/pima-indians-diabetes3.csv")
# 처음 5줄을 봅니다.
df.head(5)
# 정상과 당뇨 환자가 각각 몇 명씩인지 조사해 봅니다.
df["diabetes"].value_counts()
# 각 정보별 특징을 좀 더 자세히 출력합니다.
df.describe()
# 각 항목이 어느정도의 상관 관계를 가지고 있는지 알아봅니다. 
df.corr()
# 데이터 간의 상관 관계를 그래프로 표현해 봅니다.
colormap = plt.cm.gist_heat   #그래프의 색상 구성을 정합니다.
plt.figure(figsize=(12,12))   #그래프의 크기를 정합니다.
# 그래프의 속성을 결정합니다. vmax의 값을 0.5로 지정해 0.5에 가까울수록 밝은색으로 표시되게 합니다.
sns.heatmap(df.corr(),linewidths=0.1,vmax=0.5, cmap=colormap, linecolor='white', annot=True)
plt.show()
#plasma를 기준으로 각각 정상과 당뇨가 어느 정도 비율로 분포하는지 살펴봅니다. 
plt.hist(x=[df.plasma[df.diabetes==0], df.plasma[df.diabetes==1]], bins=30, histtype='barstacked', label=['normal','diabetes'])
plt.legend()

# 세부 정보를 X로 지정
X = df.iloc[:,0:8]
# 당뇨병 여부를 Y로 지정
y = df.iloc[:,8]
# 시퀀셜 모델
model = Sequential()
# 12개 뉴런, 입력차원은 8, 활성화 함수 ReLU 사용,2번째 밀집층으로 8개의 뉴런, 활성화 함수 ReLU 사용
model.add(Dense(12, input_dim=8, activation='relu', name='Dense_1'))
model.add(Dense(8, activation='relu', name='Dense_2'))
# 시그모이드 함수 사용
model.add(Dense(1, activation='sigmoid',name='Dense_3'))
model.summary()
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 컴파일, 실행
history=model.fit(X, y, epochs=100, batch_size=5)
```
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/iris3.csv")
# 속성을 X, 클래스를 y로 저장
X = df.iloc[:,0:4]
y = df.iloc[:,4]
# 원-핫 인코딩 처리
y = pd.get_dummies(y)
# 모델 생성
model = Sequential()
model.add(Dense(12,  input_dim=4, activation='relu'))
model.add(Dense(8,  activation='relu'))
model.add(Dense(3, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# 모델 컴파일,실행
history=model.fit(X, y, epochs=30, batch_size=5)
```
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import pandas as pd
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/sonar3.csv")
X = df.iloc[:,0:60]
y = df.iloc[:,60]
# 몇 겹으로 나눌 것인지를 결정
k = 5
# KFold 함수를 불러오고 분할하기 전에 샘플이 치우치지 않도록 섞어줌
kfold = KFold(n_splits=k, shuffle=True)
# 정확도가 채워질 빈 리스트를 준비
acc_score = []
def model_fn():
    model = Sequential()  # 딥러닝 모델의 구조를 시작
    model.add(Dense(24, input_dim=60, activation='relu'))
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    return model
# K겹 교차 검증을 이용해 k번의 학습을 실행
for train_index, test_index in kfold.split(X):  # for문에 의해서 k번 반복, spilt()에 의해 k개의 학습셋, 테스트셋으로 분리
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    model = model_fn()
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0)
    accuracy = model.evaluate(X_test, y_test)[1]  # 정확도
    acc_score.append(accuracy)  # 정확도 리스트에 저장

# k번 실시된 정확도의 평균
avg_acc_score = sum(acc_score) / k

# 결과 출력
print('정확도:', acc_score)
print('정확도 평균:', avg_acc_score)
```
