```python
import numpy as np
# 가중치와 바이어스
w11 = np.array([-2, -2])
w12 = np.array([2, 2])
w2 = np.array([1, 1])
b1 = 3
b2 = -1
b3 = -1
# 퍼셉트론
def MLP(x, w, b):
    y = np.sum(w * x) + b
    if y <= 0:
        return 0
    else:
        return 1
# NAND 게이트
def NAND(x1,x2):
    return MLP(np.array([x1, x2]), w11, b1)
# OR 게이트
def OR(x1,x2):
    return MLP(np.array([x1, x2]), w12, b2)
# AND 게이트
def AND(x1,x2):
    return MLP(np.array([x1, x2]), w2, b3)
# XOR 게이트
def XOR(x1,x2):
    return AND(NAND(x1, x2),OR(x1,x2))
# x1, x2 값을 번갈아 대입해 가며 최종 값 출력
    for x in [(0, 0), (1, 0), (0, 1), (1, 1)]:
        y = XOR(x[0], x[1])
        print("입력 값: " + str(x) + " 출력 값: " + str(y))
```
```python
# 텐서플로 라이브러리 안에 있는 케라스 API에서 필요한 함수들을 불러오기
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
# 데이터를 다루는 데 필요한 라이브러리를 불러오기
import numpy as np
# 준비된 수술 환자 데이터를 불러오기
Data_set = np.loadtxt("C:/Users/jaegy/pythonProject2/data/ThoraricSurgery3.csv", delimiter=",")
X = Data_set[:,0:16]    # 환자의 진찰 기록을 X로 지정
y = Data_set[:,16]      # 수술 1년 후 사망/생존 여부를 y로 지정
# 딥러닝 모델의 구조 결정
model = Sequential()
# 30개의 뉴런을 가지고, 입력 차원은 16, 활성화 함수는 ReLU를 사용
model.add(Dense(30, input_dim=16, activation='relu'))
# 시그모이드 함수 사용
model.add(Dense(1, activation='sigmoid'))
# 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 실행
history=model.fit(X, y, epochs=5, batch_size=16)
```
```python
# 텐서플로 라이브러리 안에 있는 케라스 API에서 필요한 함수들을 불러오기
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
# pandas 라이브러리를 불러오기
import pandas as pd
# 피마 인디언 당뇨병 데이터셋을 불러오기
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/pima-indians-diabetes3.csv")
# 처음 5줄을 봅니다.
df.head(5)
# 정상과 당뇨 환자가 각각 몇 명씩인지 조사해 봅니다.
df["diabetes"].value_counts()
# 각 정보별 특징을 좀 더 자세히 출력합니다.
df.describe()
# 각 항목이 어느정도의 상관 관계를 가지고 있는지 알아봅니다. 
df.corr()
# 데이터 간의 상관 관계를 그래프로 표현해 봅니다.
colormap = plt.cm.gist_heat   #그래프의 색상 구성을 정합니다.
plt.figure(figsize=(12,12))   #그래프의 크기를 정합니다.
# 그래프의 속성을 결정합니다. vmax의 값을 0.5로 지정해 0.5에 가까울수록 밝은색으로 표시되게 합니다.
sns.heatmap(df.corr(),linewidths=0.1,vmax=0.5, cmap=colormap, linecolor='white', annot=True)
plt.show()
#plasma를 기준으로 각각 정상과 당뇨가 어느 정도 비율로 분포하는지 살펴봅니다. 
plt.hist(x=[df.plasma[df.diabetes==0], df.plasma[df.diabetes==1]], bins=30, histtype='barstacked', label=['normal','diabetes'])
plt.legend()

# 세부 정보를 X로 지정
X = df.iloc[:,0:8]
# 당뇨병 여부를 Y로 지정
y = df.iloc[:,8]
# 시퀀셜 모델
model = Sequential()
# 12개 뉴런, 입력차원은 8, 활성화 함수 ReLU 사용,2번째 밀집층으로 8개의 뉴런, 활성화 함수 ReLU 사용
model.add(Dense(12, input_dim=8, activation='relu', name='Dense_1'))
model.add(Dense(8, activation='relu', name='Dense_2'))
# 시그모이드 함수 사용
model.add(Dense(1, activation='sigmoid',name='Dense_3'))
model.summary()
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 컴파일, 실행
history=model.fit(X, y, epochs=100, batch_size=5)
```
```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/iris3.csv")
# 속성을 X, 클래스를 y로 저장
X = df.iloc[:,0:4]
y = df.iloc[:,4]
# 원-핫 인코딩 처리
y = pd.get_dummies(y)
# 모델 생성
model = Sequential()
model.add(Dense(12,  input_dim=4, activation='relu'))
model.add(Dense(8,  activation='relu'))
model.add(Dense(3, activation='softmax'))
model.summary()
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# 모델 컴파일,실행
history=model.fit(X, y, epochs=30, batch_size=5)
```
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import pandas as pd
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/sonar3.csv")
X = df.iloc[:,0:60]
y = df.iloc[:,60]
# 몇 겹으로 나눌 것인지를 결정
k = 5
# KFold 함수를 불러오고 분할하기 전에 샘플이 치우치지 않도록 섞어줌
kfold = KFold(n_splits=k, shuffle=True)
# 정확도가 채워질 빈 리스트를 준비
acc_score = []
def model_fn():
    model = Sequential()  # 딥러닝 모델의 구조를 시작
    model.add(Dense(24, input_dim=60, activation='relu'))
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    return model
# K겹 교차 검증을 이용해 k번의 학습을 실행
for train_index, test_index in kfold.split(X):  # for문에 의해서 k번 반복, spilt()에 의해 k개의 학습셋, 테스트셋으로 분리
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    model = model_fn()
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0)
    accuracy = model.evaluate(X_test, y_test)[1]  # 정확도
    acc_score.append(accuracy)  # 정확도 리스트에 저장

# k번 실시된 정확도의 평균
avg_acc_score = sum(acc_score) / k

# 결과 출력
print('정확도:', acc_score)
print('정확도 평균:', avg_acc_score)
```

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import os
import pandas as pd

df = pd.read_csv('C:/Users/jaegy/pythonProject2/data/wine.csv', header=None)
# 와인의 속성을 X로 와인의 분류를 y로 저장
X = df.iloc[:,0:12]
y = df.iloc[:,12]
#학습셋과 테스트셋으로 나눔
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)
# 모델 구조 설정
model = Sequential()
model.add(Dense(30,  input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
#모델을 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# 학습이 언제 자동 중단 될지를 설정
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)
modelpath="C:/Users/jaegy/pythonProject2/data/model/Ch14-4-bestmodel.hdf5"
# 최적화 모델 업데이트, 저장
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)
#모델 실행
history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback,checkpointer])
# 테스트 결과 출력
score=model.evaluate(X_test, y_test)
print('Test accuracy:', score[1])
```
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
#데이터 불러오기
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/house_train.csv")
#카테고리형 변수를 0과 1로 이루어진 변수로 바꿈
df = pd.get_dummies(df)
#결측치를 전체 칼럼의 평균으로 대체
df = df.fillna(df.mean())
#데이터 사이의 상관 관계 저장
df_corr=df.corr()
#집 값과 관련이 큰 것부터 순서대로 저장
df_corr_sort=df_corr.sort_values('SalePrice', ascending=False)
#집 값을 제외한 나머지 열을 저장
cols_train=['OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF']
X_train_pre = df[cols_train]

#집 값
y = df['SalePrice'].values
#전체의 80%를 학습셋으로, 20%를 테스트셋으로 지정
X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2)
#모델의 구조를 설정
model = Sequential()
model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(30, activation='relu'))
model.add(Dense(40, activation='relu'))
model.add(Dense(1))

#모델 실행
model.compile(optimizer ='adam', loss = 'mean_squared_error')

# 20회 이상 결과가 향상되지 않으면 자동으로 중단
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)

# 모델 이름
modelpath="C:/Users/jaegy/pythonProject2/data/model/Ch15-house.hdf5"

# 최적화 모델 업데이트, 저장
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)

#실행 관련 설정(전체의 20%를 검증셋으로 설정)
history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])
# 예측 값과 실제 값, 실행 번호가 들어갈 빈 리스트 생성
real_prices =[]
pred_prices = []
X_num = []

# 25개의 샘플의 실제 값, 예측 값
n_iter = 0
Y_prediction = model.predict(X_test).flatten()
for i in range(25):
    real = y_test[i]
    prediction = Y_prediction[i]
    print("실제가격: {:.2f}, 예상가격: {:.2f}".format(real, prediction))
    real_prices.append(real)
    pred_prices.append(prediction)
    n_iter = n_iter + 1
    X_num.append(n_iter)
# 샘플 25개의 그래프

    plt.plot(X_num, pred_prices, label='predicted price')
    plt.plot(X_num, real_prices, label='real price')
    plt.legend()
    plt.show()
```
