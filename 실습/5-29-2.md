## normal model

```python
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense
import pandas as pd
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/sonar3.csv")
X = df.iloc[:,0:60]
y = df.iloc[:,60]
# 모델 설정
model = Sequential()
model.add(Dense(24,  input_dim=60, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# 모델 컴파일, 실행
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history=model.fit(X, y, epochs=200, batch_size=10)
```


## new model

```python
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
import pandas as pd
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/sonar3.csv")
X = df.iloc[:,0:60]
y = df.iloc[:,60]
# 학습 셋과 테스트 셋을 구분
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)
# 모델 설정
model = Sequential()
model.add(Dense(24,  input_dim=60, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# 모델을 컴파일,실행
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history=model.fit(X_train, y_train, epochs=200, batch_size=10)
score=model.evaluate(X_test, y_test)
print('Test accuracy:', score[1])
```

## kfold


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
import pandas as pd
df = pd.read_csv("C:/Users/jaegy/pythonProject2/data/sonar3.csv")
X = df.iloc[:,0:60]
y = df.iloc[:,60]
# 몇 겹으로 나눌 것인지를 결정
k = 5
# KFold 함수를 불러오고 분할하기 전에 샘플이 치우치지 않도록 섞어줌
kfold = KFold(n_splits=k, shuffle=True)
# 정확도가 채워질 빈 리스트를 준비
acc_score = []
def model_fn():
    model = Sequential()  # 딥러닝 모델의 구조를 시작
    model.add(Dense(24, input_dim=60, activation='relu'))
    model.add(Dense(10, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))
    return model
# K겹 교차 검증을 이용해 k번의 학습을 실행
for train_index, test_index in kfold.split(X):  # for문에 의해서 k번 반복, spilt()에 의해 k개의 학습셋, 테스트셋으로 분리
    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    model = model_fn()
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    history = model.fit(X_train, y_train, epochs=200, batch_size=10, verbose=0)
    accuracy = model.evaluate(X_test, y_test)[1]  # 정확도
    acc_score.append(accuracy)  # 정확도 리스트에 저장

# k번 실시된 정확도의 평균
avg_acc_score = sum(acc_score) / k

# 결과 출력
print('정확도:', acc_score)
print('정확도 평균:', avg_acc_score)
```
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/cda213da-c535-432e-ba63-b34caaa3a862)
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/4b07e714-1d2a-4792-952a-fc8bc02713f2)
![image](https://github.com/gryrryfh/AI-Class/assets/50912987/6132782b-82b5-4b5a-b938-7bdbea433800)
